{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation Calibration\n",
    "\n",
    "Simulation calibration tries to make the rendered camera image as similar as possible to the real one.\n",
    "This should maximize the transferability of learned policies.\n",
    "\n",
    "This performs eye-in-hand calibration. It does this via comparing segmentation masks of real and rendered images using differential evolution.\n",
    "\n",
    "There is a classical way of doing eye-in-hand calibration using robot trajectories and visual trajectories from calibration patterns. Ask Nikolaus about that.\n",
    "\n",
    "## Image Based calibration\n",
    "\n",
    "Only run the first cell once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import os.path as osp\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import pybullet as p\n",
    "\n",
    "from gym_grasping.envs.robot_sim_env import RobotSimEnv\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "\n",
    "\n",
    "#image_size = (84, 84)  # calibrate small res\n",
    "image_size = (480, 480)  # calibrate high res\n",
    "\n",
    "env = RobotSimEnv(task='stackVel', renderer='egl', max_steps=200,\n",
    "                  initial_pose='close', gripper_delay=0,\n",
    "                  gripper_act_type=\"continuous\",\n",
    "                  param_randomize=False,\n",
    "                  img_size=image_size)\n",
    "\n",
    "# Clean up the env, by removing non robot stuff\n",
    "for objIds in (env._task.objects, env._task.surfaces):\n",
    "    print(objIds)\n",
    "    for objId in objIds:\n",
    "        p.removeBody(objId, physicsClientId=env.cid)\n",
    "\n",
    "assert env.robot.gripper.act_type == 'continuous'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_fn = \"./data/kuka_iiwa/\"\n",
    "image = Image.open(\"/home/kuka/lang/robot/gym_grasping/gym_grasping/calibration/data/kuka_iiwa/2019_02_05.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image from Realsense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from robot_io.cams.realsenseSR300_librs2 import RealsenseSR300\n",
    "cam = RealsenseSR300()\n",
    "#from robot_io.kuka_iiwa.wsg50_controller import WSG50Controller\n",
    "#import time\n",
    "#gripper = WSG50Controller(max_opening_width=77)\n",
    "#gripper.open_gripper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(1)\n",
    "image, _ = cam.get_image(flip_image=True, crop=True)  # size 480x480\n",
    "\n",
    "assert image.shape == (480, 480, 3)\n",
    "if image_size != (480,480):\n",
    "    image = cv2.resize(image, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_image = False\n",
    "if save_image:\n",
    "    from PIL import Image\n",
    "    img = Image.fromarray(image)\n",
    "    img_path = \"/home/kuka/lang/robot/gym_grasping/gym_grasping/calibration/data/kuka_iiwa/2020_10_28.png\"\n",
    "    img.save(img_path)\n",
    "    print(\"saved image.\")\n",
    "\n",
    "path_old = \"/home/kuka/lang/robot/gym_grasping/gym_grasping/calibration/data/kuka_iiwa/2020_10_26.png\"\n",
    "img_old = Image.open(path_old)\n",
    "#with open(path_old, \"r\") as fo:\n",
    "#    img_old = Image.open(fo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mix = (np.array(img_old) * .5 + image * .5).round().astype(np.uint8)\n",
    "plt.imshow(mix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()\n",
    "render = env.render()\n",
    "\n",
    "assert render.shape[:2] == image_size\n",
    "fig, ax = plt.subplots(1,2)\n",
    "for x in ax: x.set_axis_off()\n",
    "fig.suptitle(\"Default Views (different aspect ratio)\")\n",
    "ax[0].set_title(\"Camera Image\")\n",
    "ax[0].imshow(image)\n",
    "ax[1].set_title(\"Env Image\")\n",
    "ax[1].imshow(render)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Threshold Camera Image\n",
    "\n",
    "In order to do a robust comparison of real image and rendered image, first extract segmentation masks of the gripper by thresholding the image. This is done by an interactive plot (but can be turned off)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact\n",
    "\n",
    "do_threshold = False\n",
    "\n",
    "dist = np.linalg.norm(np.array(image), axis=2)\n",
    "\n",
    "if do_threshold == False:\n",
    "    t = 343\n",
    "    y = 280\n",
    "    \n",
    "    masked_image = np.array(image)\n",
    "    masked_image[dist > t] = (255, 255, 255)\n",
    "    masked_image[y:,:] = (255, 255, 255)\n",
    "    \n",
    "    # set this once, don't modify\n",
    "    img_mask = dist < t\n",
    "    img_mask_cache = img_mask.copy()\n",
    "    \n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    ax.set_title(\"Threshold Result\")\n",
    "    ax.set_axis_off()\n",
    "    ax = plt.imshow(masked_image)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    %matplotlib notebook\n",
    "    import numpy as np\n",
    "    from math import pi\n",
    "    import matplotlib.pyplot as plt\n",
    "    import PIL\n",
    "\n",
    "    # start the plot\n",
    "    fig, ax = plt.subplots(1)\n",
    "    ax.set_axis_off()\n",
    "    img = ax.imshow(image)\n",
    "    plt.subplots_adjust(wspace=0.05, hspace=0, left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "    t_default = 500\n",
    "    default_target = np.array(image)\n",
    "    default_target[dist < t_default] = (255, 255, 255)\n",
    "\n",
    "    def update(t=163,y=250):\n",
    "        # redo threshold\n",
    "        image_array = np.array(image)\n",
    "        image_array[dist > t] = (255, 255, 255)\n",
    "        image_array[y:,:] = (255, 255, 255)\n",
    "        image_array[y,:] = (255, 0, 0)\n",
    "        img.set_data(image_array)\n",
    "        fig.canvas.draw()\n",
    "\n",
    "    interact(update,\n",
    "            t=(0, 500, 1),\n",
    "            y=(200, 300, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Render Default Configuration\n",
    "\n",
    "TODO(max) add code to render the un cropped view (closed gripper) with default configuration to see if we are already calibrated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "render = env.render()\n",
    "fig, ax = plt.subplots(1,3)\n",
    "for x in ax :x.set_axis_off()\n",
    "ax[0].set_title(\"Threshold Image\")\n",
    "ax[0].imshow(masked_image)\n",
    "ax[1].imshow(img_mask)\n",
    "ax[1].set_title(\"gripper=yellow?\")\n",
    "ax[2].set_title(\"Rendered Clean\")\n",
    "ax[2].imshow(render)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Alignment\n",
    "\n",
    "This code defines functions for parameterized rendering, then opens an interactive plot.\n",
    "This can be used to find a good range of parameteres to set bound for the optimization later on.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "\n",
    "#print(image.size)\n",
    "#image_width, image_height = image.size\n",
    "image_width, image_height = image.shape[:2]\n",
    "image_array = image.copy()\n",
    "\n",
    "def get_image(pos=np.array([0,0,0]),\n",
    "              orn=np.array([0,0,0]),\n",
    "              gripper=None,\n",
    "              fov=40,\n",
    "              width=image_width,\n",
    "              height=image_height):\n",
    "    \n",
    "    # set the robot calibration\n",
    "    env.params.sample[\"calib_pos\"] = pos\n",
    "    env.params.sample[\"calib_orn\"] = orn\n",
    "    env.params.sample[\"cam_fov\"] = fov\n",
    "    env.params.sample[\"gripper_joint_ul\"] = gripper\n",
    "    \n",
    "    if gripper is not None:\n",
    "        env.robot.gripper.reset_pose()\n",
    "    \n",
    "    env._render_width = width\n",
    "    env._render_height = height\n",
    "    env.camera._base_proj_matrix = env.p.computeProjectionMatrixFOV(\n",
    "        fov=fov, aspect=float(env._render_width)/env._render_height,\n",
    "        nearVal=0.01, farVal=100.0)\n",
    "    return env.render()\n",
    "\n",
    "def get_image_arr(arr,**argv):     \n",
    "    pos = np.array(arr[0:3])\n",
    "    orn = np.array(arr[3:6])\n",
    "    gripper = arr[6]\n",
    "    fov = arr[7]\n",
    "    return get_image(pos, orn, gripper, fov, **argv)\n",
    "\n",
    "# normalized intersection over union function\n",
    "def niou_func(rnd):\n",
    "    rnd_mask = np.any(rnd<100, axis=2) \n",
    "    intersection = np.sum(rnd_mask * img_mask)\n",
    "    union = np.sum(rnd_mask + img_mask)\n",
    "    niou = 1 - intersection / union\n",
    "    return niou\n",
    "\n",
    "minscore = 1e30\n",
    "\n",
    "def testfunc(arr):\n",
    "    rnd = get_image_arr(arr)\n",
    "    #norm = np.linalg.norm(rnd-default_target)\n",
    "    norm = niou_func(rnd)\n",
    "    #print\n",
    "    global minscore\n",
    "    if norm < minscore:\n",
    "        print(minscore, \"[\", end='')\n",
    "        print(*arr, sep=\", \", end='')\n",
    "        print(\"]\")\n",
    "        minscore = norm\n",
    "    return(norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "from math import pi\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL\n",
    "\n",
    "#df = dict(x=-.004, y=0, z=.007, a=0, b=0, c=0, gripper=0.0455, fov=42)\n",
    "default_arr = [-8.11760879e-04,  5.91212989e-03,  4.63097354e-04,  2.08804174e-02, 1.21849894e-02,  1.49459515e-02,  4.50389914e-02,  4.40690316e+01]\n",
    "#default_arr = [-5.93110931e-04,  4.87719789e-03, -1.15584238e-06,  2.63053764e-02, 1.27284190e-02,  1.57081386e-02,  4.46852048e-02,  4.35229641e+01]\n",
    "\n",
    "df = dict(zip(('x','y','z','a','b','c','gripper','fov'), default_arr))\n",
    "\n",
    "# start the plot\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_axis_off()\n",
    "line = ax.imshow(np.zeros(masked_image.shape))\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0, left=0, bottom=0, right=1, top=1)\n",
    "\n",
    "def update(x=df['x'], y=df['y'], z=df['z'],\n",
    "           a=df['a'], b=df['b'], c=df['c'],\n",
    "           gripper=df['gripper'], fov=df['fov']):\n",
    "    \n",
    "    pos = np.array([x, y, z])\n",
    "    orn = np.array([a, b, c])\n",
    "    rnd = get_image(pos, orn, gripper, fov)\n",
    "    #PIL.Image.fromarray(rnd).save(\"rendered.png\")\n",
    "    \n",
    "    # redo threshold\n",
    "    mix = (masked_image * .5 + rnd * .5).round().astype(np.uint8)\n",
    "    \n",
    "    line.set_data(mix)   \n",
    "    fig.canvas.draw()\n",
    "    \n",
    "    niou = niou_func(rnd)\n",
    "    print(\"score niou\", niou)\n",
    "    print(\"score l2\", np.linalg.norm(rnd-image_array))\n",
    "\n",
    "# these are steps\n",
    "interact(update,\n",
    "        x=(-.03, .03, .001),\n",
    "        y=(-.03, .03, .001),\n",
    "        z=(-.02, .04, .001),\n",
    "        \n",
    "        a=(-0.05, 0.05, .001),\n",
    "        b=(-0.05, 0.05, .001),\n",
    "        c=(-0.05, 0.05, .001),\n",
    "        gripper=(.04, .05, .001),\n",
    "        fov = (41, 45, 0.1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(testfunc(default_arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "This code runs the differential evolution optimization, usually takes a while ~15min."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global minscore\n",
    "minscore = 1e30\n",
    "\n",
    "from scipy.optimize import differential_evolution\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "bounds = [(-.03, .03),  # x\n",
    "          (-.03, .03),  # y\n",
    "          (-.02, .04),  # z\n",
    "          (-0.05, 0.05),  # a\n",
    "          (-0.05, 0.05),  # b\n",
    "          (-0.05, 0.05),  # c\n",
    "          (.04, .05),  # gripper_joint_ul\n",
    "          (41, 45)]\n",
    "\n",
    "result = differential_evolution(testfunc, bounds,\n",
    "                                maxiter=75000, polish=True)\n",
    "\n",
    "#x0 = [np.mean(x) for x in bounds]\n",
    "#result = minimize(testfunc, x0=x0, method=\"Nelder-Mead\")\n",
    "\n",
    "print(\"\\nOptimization done!\")\n",
    "print(result.x, result.fun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[-1.34050847e-03, -1.22241527e-03,  1.94246598e-03,  1.83346818e-02,\n",
    "  1.47678984e-02,  1.13706384e-02,  X,  X]\n",
    "\n",
    "[-1.58132880e-03 -1.65116112e-03 -2.10224659e-04  3.20026306e-02\n",
    "  1.15026284e-02  1.16134438e-02  X  X] 0.09725906277630414\n",
    "\n",
    "[-1.58417016e-03  4.77775224e-03  2.82711839e-04  2.50235106e-02\n",
    "  9.72836616e-03  1.14202937e-02  X  4.35847151e+01] 0.09756097560975607\n",
    "\n",
    "XXX Small Res\n",
    "[-4.04621259e-04  3.56216508e-03  3.36449559e-04  2.58699097e-02\n",
    "  1.54623827e-02  1.60939934e-02  4.46233639e-02  4.32280177e+01] 0.10060711188204685\n",
    "\n",
    "XXX High Res run 1 & 2\n",
    "0.034534877088918 [-7.32462050e-04  5.59790929e-03  4.51445027e-04  2.46986871e-02\n",
    "  1.14995637e-02  1.53770490e-02  4.49168715e-02  4.39039437e+01]\n",
    "\n",
    "0.03515413737155215 [-5.93110931e-04,  4.87719789e-03, -1.15584238e-06,  2.63053764e-02,\n",
    "  1.27284190e-02,  1.57081386e-02,  4.46852048e-02,  4.35229641e+01]\n",
    "\n",
    "Run ?? \n",
    "\n",
    "[-8.11760879e-04,  5.91212989e-03,  4.63097354e-04,  2.08804174e-02,\n",
    "        1.21849894e-02,  1.49459515e-02,  4.50389914e-02,  4.40690316e+01]\n",
    "\n",
    "[-8.25197132e-04,  8.80486131e-03, -8.23005900e-04,  2.89505485e-02,\n",
    "  1.16251534e-02,  1.46831751e-02,  4.48741467e-02,  4.45902255e+01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_arr = [0.011284435936295039, 0.02998802466639384, -0.00833947711031245, -0.04873989515666205, 0.031239671009381145, 0.04826560796124244, 0.040152562068615186, 41.774574723911286]\n",
    "print(testfunc(default_arr))\n",
    "\n",
    "default_arr = [-8.11760879e-04,  5.91212989e-03,  4.63097354e-04,  2.08804174e-02, 1.21849894e-02,  1.49459515e-02,  4.50389914e-02,  4.40690316e+01]\n",
    "print(testfunc(default_arr))\n",
    "\n",
    "#default_arr = [-5.93110931e-04,  4.87719789e-03, -1.15584238e-06,  2.63053764e-02, 1.27284190e-02,  1.57081386e-02,  4.46852048e-02,  4.35229641e+01]\n",
    "#print(testfunc(default_arr))\n",
    "\n",
    "default_arr = [-0.00833239907437136, 0.029619700487285492, -0.019568588856726285, -0.04760457876766309, -0.010309110682057443, -0.03115142369765686, 0.04370905410829578, 41.001146865380086]\n",
    "print(testfunc(default_arr))\n",
    "\n",
    "#default_arr = [-8.25197132e-04,  8.80486131e-03, -8.23005900e-04,  2.89505485e-02,  1.16251534e-02,  1.46831751e-02,  4.48741467e-02,  4.45902255e+01]\n",
    "#default_arr = [-0.0008392997212615084, 0.008794301929382159, -0.0008297287274300752, 0.028990369747127435, 0.011486481116888906, 0.014602577989890647, 0.04488457868564247, 44.59207289541456]\n",
    "#default_arr = [-0.0010442705210949464, 0.0051371498304054524, -0.0017210247957249432, 0.01877539567147731, 0.01970857299167643, 0.009477141233107732, 0.044506577350280574, 43.59444713296427]\n",
    "default_arr = [0.00012021346287341083, 0.004711761531908094, -0.0007818706874626134, 0.04217865640212694, 0.02944752036043126, 0.02529005601937725, 0.04434623212006212, 43.406409868283404]\n",
    "print(testfunc(default_arr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-Tune with gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = minimize(testfunc, x0=default_arr, method=\"Nelder-Mead\") \n",
    "#result = minimize(testfunc, x0=arr, method=\"L-BFGS-B\") \n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "dt_now = datetime.datetime.now().__str__()\n",
    "\n",
    "arr = result.x.tolist()\n",
    "pos = arr[0:3]\n",
    "orn = arr[3:6]\n",
    "gripper = arr[6]\n",
    "fov = arr[7]\n",
    "\n",
    "rest_pose = [-1.57079633, 0.6981317, 0, -1.3962634, 0, 1.04719755, 0, 0, 0.0400, 0.0400, 0.0000]\n",
    "calibration_dict = dict(cam_fov=fov, cam_pos=pos, cam_orn=orn, \n",
    "                        gripper_joint_ul=gripper,\n",
    "                        rest_pose=rest_pose, datetime=dt_now)\n",
    "\n",
    "json_str = json.dumps(calibration_dict, indent=4, separators=(',', ': '))\n",
    "print(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_calib = True\n",
    "\n",
    "if save_calib:\n",
    "    calib_latest_path = \"/home/kuka/lang/robot/gym_grasping/gym_grasping/robots/models/kuka_iiwa/calibration_latest.json\"\n",
    "\n",
    "    with open(calib_latest_path, \"w\") as fo:\n",
    "        json.dump(calibration_dict, fo, indent=4, separators=(',', ': '))\n",
    "        fo.write(\"\\n\")\n",
    "    print(\"saved calibration file.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.ioff()\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0, left=0, bottom=0, right=1, top=1)\n",
    "ax.set_axis_off()\n",
    "\n",
    "render # f\n",
    "rnd = get_image_arr(arr)\n",
    "#niou = niou_func(rnd)\n",
    "#print(niou)\n",
    "#rnd = render\n",
    "mix = (masked_image * .5 + rnd * .5).round().astype(np.uint8)\n",
    "\n",
    "ax.imshow(mix)\n",
    "ax.text(100, 300, \"combined image\",  fontsize=14, verticalalignment='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_calibrated = RobotSimEnv(task='stackVel', renderer='egl', max_steps=200,\n",
    "                             initial_pose='close', gripper_delay=0,\n",
    "                             gripper_act_type=\"continuous\",\n",
    "                             param_randomize=False,\n",
    "                             img_size=image_size)\n",
    "\n",
    "for objIds in (env_calibrated._task.objects, env_calibrated._task.surfaces):\n",
    "    print(objIds)\n",
    "    for objId in objIds:\n",
    "        p.removeBody(objId, physicsClientId=env_calibrated.cid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dt_now)\n",
    "rnd_env = env_calibrated.render()\n",
    "\n",
    "plt.ioff()\n",
    "fig, ax = plt.subplots(1)\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0, left=0, bottom=0, right=1, top=1)\n",
    "ax.set_axis_off()\n",
    "\n",
    "mix = (masked_image * .5 + rnd_env * .5).round().astype(np.uint8)\n",
    "\n",
    "ax.imshow(mix)\n",
    "ax.text(100, 300, \"combined image\",  fontsize=14, verticalalignment='top')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resize View\n",
    "\n",
    "While we want to do the optimization with a full view of the image, we usually want to do RL on small resized images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_square(image):\n",
    "    if isinstance(image, np.ndarray):\n",
    "        image = PIL.Image.fromarray(image)\n",
    "    width, height = image.size\n",
    "        \n",
    "    assert(width > height)\n",
    "    border = (width - height)//2\n",
    "    # left, upper, right, lower\n",
    "    box = (border, 0, width-border, height)  \n",
    "    image_square = image.crop(box) \n",
    "    return image_square\n",
    "\n",
    "image_square = make_square(image)\n",
    "rendered = get_image_arr(arr)\n",
    "render_square = make_square(rendered)\n",
    "w_sq,h_sq = image_square.size\n",
    "rendered_small = get_image_arr(arr,width=w_sq,height=h_sq)\n",
    "\n",
    "# print\n",
    "print(\"rendered image size\", image.size, \"after cropping\", image_square.size)\n",
    "print(\"rendered small image size\", rendered_small.shape)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1,3)\n",
    "for x in ax: x.set_axis_off()\n",
    "fig.suptitle(\"Cropped Images (second and third should be same)\")\n",
    "ax[0].imshow(image_square)\n",
    "ax[0].set_title(\"cropped camera\")\n",
    "ax[1].imshow(render_square)\n",
    "ax[1].set_title(\"cropped render\")\n",
    "ax[2].imshow(rendered_small)\n",
    "ax[2].set_title(\"render small\")\n",
    "plt.show()\n",
    "\n",
    "render_cmb = (np.array(render_square) - np.array(rendered_small))\n",
    "print(\"sum of differences\", render_cmb.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Camera Intrinsics\n",
    "\n",
    "We can compare the factory calibration fov to the value we found. This can be used to validate the quality of the calibration.\n",
    "\n",
    "TODO(add code for getting camera calibration from API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import atan, pi\n",
    "instrinsics = dict(\n",
    "    width = 1280,\n",
    "    height = 720,\n",
    "    ppx = 632.806,\n",
    "    ppy = 368.559,\n",
    "    fx = 926.835,\n",
    "    fy = 926.835)\n",
    "\n",
    "fov_v = 2*atan(instrinsics[\"width\"]/(2*instrinsics[\"fx\"]))*180/pi \n",
    "fov_h = 2*atan(instrinsics[\"height\"]/(2*instrinsics[\"fy\"]))*180/pi\n",
    "\n",
    "print(\"ppx_deviation=\",instrinsics[\"width\"]/2-instrinsics[\"ppx\"])\n",
    "print(\"ppy_deviation=\",instrinsics[\"height\"]/2-instrinsics[\"ppy\"])\n",
    "print()\n",
    "\n",
    "print(\"fov v =\", fov_v)\n",
    "print(\"fov h =\", fov_h)\n",
    "\n",
    "fov_calib = arr[7]\n",
    "print(\"fov c =\",fov_calib )\n",
    "\n",
    "\n",
    "factory_deviation = (fov_h - fov_calib)/  fov_h\n",
    "print(\"Deviation to factory: {}[%]\".format(factory_deviation * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
