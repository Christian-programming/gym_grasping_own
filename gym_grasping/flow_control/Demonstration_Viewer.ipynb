{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demonstration View\n",
    "\n",
    "View a demonstration by sliding through the frames.\n",
    "This also plots the z height."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# default parameter values\n",
    "segment_height = False\n",
    "segment_labels = False  # this seems deprecated\n",
    "segment_imgheight = False\n",
    "movement_threshold = None\n",
    "keep_frames_method = \"sparse\"\n",
    "gripper_close_steps = 30\n",
    "demonstration_type = \"grasp_insert\"\n",
    "\n",
    "#recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/lego\", 3\n",
    "#keep_frames_method = \"dense\"\n",
    "#gripper_close_steps = 10\n",
    "#segment_colors = [(1,0,0), (0,0,1), (0,0,1)]\n",
    "#segment_thresholds = [.75,.60, .60]\n",
    "\n",
    "# recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/wheel\", 17\n",
    "# segment_colors = [\"bw\", (1, 0, 0), (1, 0, 0)]\n",
    "# segment_thresholds = [.30, .75, .75]\n",
    "# segment_labels = (2, False, False)\n",
    "\n",
    "#recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/pick_stow\", 2\n",
    "#segment_colors = [(0, 0, 1), \"keep_black\", \"keep_black\"]\n",
    "#segment_thresholds = [.56, .45, .45]\n",
    "#segment_imgheight = (False, 260, 260)\n",
    "\n",
    "# recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/transfer_blue_block\", 0\n",
    "# demonstration_type = \"grasp\"\n",
    "# segment_colors = [(0, 0, 1),(0, 0, 1)]\n",
    "# segment_thresholds = [.56, .56]\n",
    "\n",
    "# recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/transfer_orange\", 0\n",
    "# demonstration_type = \"grasp\"\n",
    "# segment_colors = [(130/255, 80/255, 59/255),(130/255, 80/255, 59/255)]\n",
    "# segment_thresholds = [.43, .43]\n",
    "\n",
    "#recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/navigate_blue_letter_block\", 0\n",
    "#demonstration_type = \"navigate\"\n",
    "#segment_colors = [(0, 0, 1),(0, 0, 1)]\n",
    "#segment_thresholds = [.56, .56]\n",
    "\n",
    "# recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/sick_vacuum/\", 4\n",
    "# keep_frames_skip = [(110,130)]\n",
    "# segment_colors = [(0, 0, 1), \"bw\"]\n",
    "# segment_thresholds = [.65, .70]\n",
    "\n",
    "#recording, episode_num = \"/home/argusm/sick_combine/\", 3\n",
    "#segment_colors = [(0, 0, 1), \"keep_black\"]\n",
    "#segment_thresholds = [.60, .48]\n",
    "#segment_imgheight = (False, 190)\n",
    "\n",
    "recording, episode_num = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/car_screwdriver/\", 0\n",
    "demonstration_type = \"grasp\"\n",
    "segment_colors = [\"keep_black\", \"keep_black\", \"bw\"]\n",
    "segment_thresholds = [.67, .67, .59]\n",
    "\n",
    "state_recording_fn = \"{}/episode_{}.npz\".format(recording, episode_num)\n",
    "flow_recording_fn = \"{}/episode_{}.npz\".format(recording, episode_num)\n",
    "state_recording = np.load(state_recording_fn)[\"robot_state_full\"]\n",
    "actions = np.load(state_recording_fn)[\"actions\"]\n",
    "ee_positions = state_recording[:,:3]\n",
    "flow_recording = np.load(flow_recording_fn)[\"rgb_unscaled\"]\n",
    "try:\n",
    "    seg_masks = np.load(flow_recording_fn)[\"seg_masks\"]\n",
    "except (KeyError,ValueError):\n",
    "    seg_masks = None\n",
    "\n",
    "print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep Frames\n",
    "\n",
    "decide which frames to keep, saved as per-frame boolean array.\n",
    "\n",
    "1. Decisison based on gripper state\n",
    "2. Decision based on (optinal subsampling)\n",
    "3. Decision based on skip variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRIPPER_OPEN = 1.0\n",
    "GRIPPER_CLOSE = -1.0\n",
    "DEMO_STEP = 20\n",
    "\n",
    "# use actions here instead of state position recordings as these\n",
    "# are more direct/ reliable\n",
    "gr_actions = actions[:, -1]\n",
    "num_frames = flow_recording.shape[0]-1\n",
    "keysteps = np.where(np.diff(gr_actions))[0]\n",
    "\n",
    "if demonstration_type == \"navigate\":\n",
    "    gr_actions[-1] = GRIPPER_CLOSE\n",
    "    demonstration_type = \"grasp\"\n",
    "\n",
    "# keystep is the step just before closing\n",
    "assert(gr_actions[keysteps[0]] == GRIPPER_OPEN)\n",
    "assert(gr_actions[keysteps[0]+1] == GRIPPER_CLOSE)\n",
    "\n",
    "# divide sequence into steps, defined by gripper action\n",
    "segment_steps = np.zeros(gr_actions.shape)\n",
    "segment_steps[keysteps+1] = 1\n",
    "segment_steps = np.cumsum(segment_steps).astype(int)\n",
    "\n",
    "# keystep, just before closing in step 0\n",
    "# afterwards we are in step 1\n",
    "assert(segment_steps[keysteps[0]] == 0)  # close\n",
    "assert(segment_steps[keysteps[0]+1] == 1)  # open\n",
    "\n",
    "def g2txt(step):\n",
    "    return [\"close\",\"open\"][gr_actions[step].astype(int)]\n",
    "\n",
    "print(\"keysteps\", keysteps)\n",
    "print(\"demonstration type:\", demonstration_type)\n",
    "if demonstration_type == \"grasp\":\n",
    "    assert(len(keysteps) == 1)\n",
    "    grip_step = keysteps[0]  \n",
    "elif demonstration_type == \"grasp_insert\":\n",
    "    assert(len(keysteps) == 2)\n",
    "    grip_step = keysteps[0]\n",
    "    open_step = keysteps[1]\n",
    "    print(\"grip_step\", grip_step, g2txt(grip_step))\n",
    "    print(\"open_step\", open_step, g2txt(open_step))\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide which frames to keep, after gripping mask a few steps\n",
    "if keep_frames_method == \"all\":\n",
    "    keep_array = np.ones(gr_actions.shape, dtype=bool)\n",
    "elif keep_frames_method == \"dense\":\n",
    "    keep_array = np.ones(gr_actions.shape, dtype=bool)\n",
    "    keep_array[grip_step:grip_step+gripper_close_steps] = False\n",
    "elif keep_frames_method == \"sparse\":\n",
    "    keep_array = np.zeros(gr_actions.shape, dtype=bool)\n",
    "    keep_array[::DEMO_STEP] = True\n",
    "    keep_array[keysteps] = True\n",
    "    keep_array[grip_step+1:grip_step+1+gripper_close_steps] = False  \n",
    "else:\n",
    "    raise ValueError\n",
    "\n",
    "keep_array_old = keep_array.copy()\n",
    "# manuall skip a few steps\n",
    "if \"keep_frames_skip\" in locals():\n",
    "    print(\"skipping frames:\", keep_frames_skip)\n",
    "    skip = np.zeros(gr_actions.shape, dtype=int)\n",
    "    for (start, stop) in keep_frames_skip:\n",
    "        skip[start] = 1\n",
    "        skip[stop] = -1\n",
    "    skip = np.cumsum(skip).astype(bool)\n",
    "    keep_array[start-1] = True\n",
    "    keep_array[skip] = False\n",
    "\n",
    "if movement_threshold is not None:\n",
    "    # append a entry here as diff has of n-1\n",
    "    movement = np.linalg.norm(np.diff(ee_positions[:,0:3], axis=0, append=((0,0,0),)), axis=1)\n",
    "    movement_mask = movement < movement_threshold    \n",
    "    keep_array[movement_mask] = False\n",
    "\n",
    "# double check that we retain all keep steps\n",
    "assert(np.all(keep_array[keysteps]))\n",
    "\n",
    "keep_fn = flow_recording_fn.replace(\".npz\", \"_keep.npz\")\n",
    "np.savez(keep_fn, keep=keep_array, key=keysteps)\n",
    "print(\"Saved to\", keep_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify keep frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_frames = flow_recording.shape[0]-1\n",
    "x = np.linspace(0, 2 * np.pi)\n",
    "fig, (ax, ax2) = plt.subplots(2, 1)\n",
    "line = ax.imshow(flow_recording[0])\n",
    "ax.set_axis_off()\n",
    "ax2.plot(state_recording[:, -2], label=\"grip raw\")\n",
    "ax2.plot(segment_steps/10,label=\"steps\")\n",
    "ax2.plot(keep_array, label=\"keep\")\n",
    "ax2.plot((gr_actions+1)/2, label=\"gripper action\")\n",
    "ax2.set_ylabel(\"value\")\n",
    "ax2.set_xlabel(\"frame number\")\n",
    "vline = ax2.axvline(x=2, color=\"k\")\n",
    "ax2.legend()\n",
    "def update(w):\n",
    "    vline.set_data([w,w], [0,1])\n",
    "    line.set_data(flow_recording[w])\n",
    "    fig.canvas.draw_idle()\n",
    "slider_w = widgets.IntSlider(min=0, max=num_frames, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "interact(update, w=slider_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask View\n",
    "\n",
    "Mask out the foreground object so that foreground specific flow can be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "\n",
    "def erode_mask(mask):\n",
    "    mask = ndimage.binary_closing(mask, iterations=2)\n",
    "    mask = ndimage.morphology.binary_erosion(mask, iterations=4)\n",
    "    return mask\n",
    "\n",
    "def label_mask(mask, i):\n",
    "    # this computes the connected components\n",
    "    labels, num = measure.label(mask, background=0, return_num=True)\n",
    "    label_id, label_count = np.unique(labels, return_counts=True)\n",
    "    # find the biggest component here.\n",
    "    #np.argsort(label_count)\n",
    "    #print(label_count)\n",
    "    mask = (labels == 0)\n",
    "    return mask\n",
    "\n",
    "    # create a segmentation mask\n",
    "def get_mask(frame, i=None, threshold=0):\n",
    "    \"\"\"\n",
    "    create segmentation mask for single frame\n",
    "    Args:\n",
    "        frame\n",
    "        i index of frame\n",
    "        threshold\n",
    "    Returns:\n",
    "        mask: binary numpy array, with False == keep\n",
    "    \"\"\"    \n",
    "    step = segment_steps[i]\n",
    "    image = frame.copy()\n",
    "    color_choice = segment_colors[step]\n",
    "    print(\"cc\", color_choice)\n",
    "    \n",
    "    if color_choice == \"bw\":  # this is for the wheel task\n",
    "        tmp =  np.linalg.norm(image/255, axis=2) / 3**.5\n",
    "        mask = tmp > threshold\n",
    "    elif color_choice == \"keep_black\":\n",
    "        tmp =  np.linalg.norm(image/255, axis=2) \n",
    "        mask = tmp < threshold        \n",
    "    else:\n",
    "        color_choice = np.array(color_choice)    \n",
    "        tmp = np.linalg.norm(image * color_choice, axis=2) / np.linalg.norm(image, axis=2) \n",
    "        mask = tmp > threshold\n",
    "    \n",
    "    mask = erode_mask(mask)\n",
    "    \n",
    "    if segment_height and segment_height[step]:\n",
    "        depth2 = transform_depth(depth[i], np.linalg.inv(T_tcp_cam))\n",
    "        mask2 = get_mask_depth(depth2, 600, 1550)\n",
    "        mask[mask2] = True\n",
    "    \n",
    "    if segment_labels:\n",
    "        mask = ndimage.morphology.binary_closing(mask, iterations=4)\n",
    "        mask = label_mask(mask, i)\n",
    "    \n",
    "    if segment_imgheight and segment_imgheight[step]:\n",
    "        value = segment_imgheight[step]\n",
    "        mask[:value,:] = False\n",
    "    \n",
    "    if step == 0:\n",
    "#         plt.imshow(mask)\n",
    "        mask_lefthalf = np.zeros(mask.shape)\n",
    "        mask_lefthalf[:, :330] = True\n",
    "        mask = np.logical_not(np.logical_not(mask) * mask_lefthalf)\n",
    "#         plt.imshow(mask)\n",
    "        \n",
    "    \n",
    "    return mask\n",
    "\n",
    "#\n",
    "# Plot \n",
    "print(\"Colored stuff is keept - mask==True\")\n",
    "print(\"Segments:\", keysteps)\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "line = ax.imshow(flow_recording[25])\n",
    "ax.set_axis_off()\n",
    "def update(i, t):\n",
    "    # detect first frame of next step\n",
    "    first_frame = i==0 or i-1 in keysteps\n",
    "    if first_frame:\n",
    "        step = segment_steps[i]\n",
    "        new_t = segment_thresholds[step]\n",
    "        print(\"setting\", new_t)\n",
    "        slider_t.value = new_t*100\n",
    "\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = get_mask(image, i=i, threshold=t/100)    \n",
    "    image[np.logical_not(mask)] = 255,255,255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "\n",
    "slider_i = widgets.IntSlider(min=0, max=num_frames, step=1, value=0,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_t = widgets.IntSlider(min=0, max=100, step=1, value=segment_thresholds[0]*100,\n",
    "                             layout=Layout(width='70%'))\n",
    "interact(update, i=slider_i, t=slider_t)\n",
    "\n",
    "print(\"len\", len(segment_colors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = np.zeros(flow_recording.shape[:3], dtype=bool)\n",
    "switch_frame = grip_step\n",
    "print(\"switching at:\", switch_frame)\n",
    "for c,t in zip(segment_colors, segment_thresholds):\n",
    "    print(c,t)\n",
    "print()\n",
    "\n",
    "for i in range(len(flow_recording)):\n",
    "    try:\n",
    "        step = segment_steps[i]\n",
    "        threshold = segment_thresholds[step]\n",
    "    except IndexError:\n",
    "        break\n",
    "    mask = get_mask(flow_recording[i], i, threshold)\n",
    "    masks[i] = mask\n",
    "\n",
    "print(np.mean(masks) * 100, \"percent of pixels fg\")\n",
    "if folder_format == 'max':\n",
    "    mask_fn = flow_recording_fn.replace(\"_img.npz\", \"_mask.npz\")\n",
    "else:\n",
    "    mask_fn = flow_recording_fn.replace(\".npz\", \"_mask.npz\")\n",
    "np.savez(mask_fn, mask=masks)\n",
    "print(\"Saved to\", mask_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify masking results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "line = ax.imshow(masks[25])\n",
    "ax.set_axis_off()\n",
    "\n",
    "def update(i):\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = masks[i]\n",
    "    print(\"mask shape\", mask.shape)\n",
    "    image[np.logical_not(mask)] = 255, 255, 255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "slider_i2 = widgets.IntSlider(min=0, max=num_frames, step=1, value=25,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masking based on Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_data = np.load(state_recording_fn)\n",
    "#keys = list(episode_data.keys())\n",
    "camera_calibration = dict(width=640,height=480,\n",
    "                     fx = 617.8902587890625, fy=617.8903198242188, \n",
    "                     ppx=315.20367431640625, ppy=245.70614624023438 )\n",
    "\n",
    "\n",
    "T_tcp_cam = np.array([\n",
    "    [0.99987185, -0.00306941, -0.01571176, 0.00169436],\n",
    "    [-0.00515523, 0.86743151, -0.49752989, 0.11860651],\n",
    "    [0.015156,    0.49754713,  0.86730453, -0.18967231],\n",
    "    [0., 0., 0., 1.]])\n",
    "\n",
    "depth = episode_data[\"depth_imgs\"]\n",
    "depth_scale = 8000\n",
    "\n",
    "i = 200\n",
    "print(\"loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_depth(depth_image, transformation):\n",
    "    \"\"\"\n",
    "    Transform a depth image into a point cloud with one point for each\n",
    "    pixel in the image, using the camera transform for a camera\n",
    "    centred at cx, cy with field of view fx, fy.\n",
    "\n",
    "    depth is a 2-D ndarray with shape (rows, cols) containing\n",
    "    depths from 1 to 254 inclusive. The result is a 3-D array with\n",
    "    shape (rows, cols, 3). Pixels with invalid depth in the input have\n",
    "    NaN for the z-coordinate in the result.\n",
    "    \"\"\"\n",
    "    assert(camera_calibration)\n",
    "    assert(camera_calibration[\"width\"] == depth_image.shape[1])\n",
    "    assert(camera_calibration[\"height\"] == depth_image.shape[0])\n",
    "\n",
    "    C_X = camera_calibration[\"ppx\"]\n",
    "    C_Y = camera_calibration[\"ppy\"]\n",
    "    F_X = camera_calibration[\"fx\"]\n",
    "    F_Y = camera_calibration[\"fy\"]\n",
    "    \n",
    "    rows, cols = depth_image.shape\n",
    "    c, r = np.meshgrid(np.arange(cols), np.arange(rows), sparse=True)\n",
    "    \n",
    "    z = depth_image\n",
    "    x = z * (c - C_X) / F_X\n",
    "    y = z * (r - C_Y) / F_Y\n",
    "    o = np.ones(z.shape)\n",
    "    \n",
    "    tmp = np.stack((x, y, z, o), axis=2)\n",
    "    tmp2 = tmp @ transformation\n",
    "    tmp3 = tmp2[:, :, :3] / tmp2[:, :, 3, np.newaxis]\n",
    "    return tmp3[:,:,2]\n",
    "\n",
    "\n",
    "depth_flat = transform_depth(depth[i], np.linalg.inv(T_tcp_cam))\n",
    "fig, (ax,ax2) = plt.subplots(1,2)\n",
    "line = ax.imshow(depth_flat)\n",
    "ax2.plot(np.sort(depth[i].flatten()))\n",
    "ax2.plot(np.sort(depth_flat.flatten()))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_depth(frame, l, h):\n",
    "    mask = np.logical_or(frame < l/depth_scale, frame > h/depth_scale)\n",
    "    mask = np.logical_not(mask)\n",
    "    return mask\n",
    "\n",
    "def erode_mask(mask):\n",
    "    return mask\n",
    "    mask = ndimage.binary_closing(mask, iterations=5)\n",
    "    mask = ndimage.morphology.binary_erosion(mask, iterations=10)\n",
    "    return mask\n",
    "\n",
    "x = np.linspace(0, 2 * np.pi)\n",
    "fig, ax = plt.subplots(1)\n",
    "line = ax.imshow(flow_recording[0])\n",
    "\n",
    "def update(w,l,h):\n",
    "    depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "    mask = get_mask_depth(depth2, l, h)\n",
    "    mask = erode_mask(mask)\n",
    "    mask = np.logical_not(mask)\n",
    "    display_image = flow_recording[w].copy()\n",
    "    display_image[mask] = 0\n",
    "    line.set_data(display_image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "depth_min, depth_max = int(depth.min()*depth_scale), int(depth.max()*depth_scale)\n",
    "slider_w = widgets.IntSlider(min=0,max=num_frames,step=1,value=205,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_l = widgets.IntSlider(min=depth_min,max=depth_max,step=1,value=1560,\n",
    "                             layout=Layout(width='70%'))\n",
    "slider_h = widgets.IntSlider(min=depth_min,max=depth_max,step=1,value=1650,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update,w=slider_w,l=slider_l,h=slider_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next steps: anneal the edge, and run connected component algorithm.\n",
    "from scipy import ndimage\n",
    "\n",
    "w = slider_w.value\n",
    "l = slider_l.value\n",
    "h = slider_h.value\n",
    "print(\"w={w}, l={l}, h={h}\".format(w=w,l=l,h=h))\n",
    "\n",
    "depth2 = transform_depth(depth[w], np.linalg.inv(T_tcp_cam))\n",
    "mask_s = get_mask_depth(depth2, l, h)\n",
    "mask_s = erode_mask(mask_s.copy())\n",
    "mask_s = np.logical_not(mask_s)\n",
    "display_image = flow_recording[w].copy()\n",
    "display_image[mask_s] = 0\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "line = ax.imshow(display_image)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_low = slider_l.value\n",
    "threshold_high = slider_h.value\n",
    "\n",
    "masks = np.zeros(flow_recording.shape[:3],dtype=bool)\n",
    "\n",
    "for i in range(len(flow_recording)):\n",
    "    mask = get_mask_depth(depth[i], threshold_low, threshold_high)\n",
    "    mask = erode_mask(mask)\n",
    "    masks[i] = mask\n",
    "\n",
    "print(np.mean(masks) * 100, \"percent of pixels fg\")\n",
    "mask_fn = flow_recording_fn.replace(\".npz\",\"_mask.npz\")\n",
    "np.savez(mask_fn, mask=masks)\n",
    "print(\"Saved to\",mask_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,1)\n",
    "line = ax.imshow(masks[25])\n",
    "ax.set_axis_off()\n",
    "\n",
    "def update(i):\n",
    "    image = flow_recording[i].copy()\n",
    "    mask = masks[i]\n",
    "    image[mask] = 255,255,255\n",
    "    line.set_data(image)\n",
    "    fig.canvas.draw_idle()\n",
    "    \n",
    "slider_i2 = widgets.IntSlider(min=0,max=num_frames,step=1,value=200,\n",
    "                             layout=Layout(width='70%'))\n",
    "\n",
    "interact(update, i=slider_i2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
