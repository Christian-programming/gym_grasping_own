{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.spatial\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "object_dir_path = \"/home/zimmermc/projects/RGBD_Fusion/data/pose_estimation/\"\n",
    "object_dirs = [name for name in os.listdir(object_dir_path) if os.path.isdir(os.path.join(object_dir_path, name))]\n",
    "object_name = \"wd_40\"\n",
    "\n",
    "print(object_dirs)\n",
    "print(object_name)\n",
    "\n",
    "assert(object_name in object_dirs)\n",
    "object_dir = os.path.join(object_dir_path, object_name)\n",
    "obj_files = sorted(os.listdir(object_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "rgb_files = []\n",
    "depth_files = []\n",
    "for fn in obj_files:\n",
    "    if fn.startswith(\"rgb_\") and fn.endswith(\".png\"):\n",
    "        file_path = os.path.join(object_dir, fn)\n",
    "        image = PIL.Image.open(file_path)\n",
    "        rgb_files.append(image)\n",
    "        \n",
    "    elif fn.startswith(\"depth_\") and fn.endswith(\".png\"):\n",
    "        file_path = os.path.join(object_dir, fn)\n",
    "        image = PIL.Image.open(file_path)\n",
    "        depth_files.append(image)\n",
    "\n",
    "assert len(rgb_files) == len(depth_files)\n",
    "depth_scaling = 0.000125\n",
    "print(\"images loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_dir_path = \"/home/argusm/lang/flow_control/pose_estimation/\"\n",
    "mask_dir = os.path.join(mask_dir_path, object_name)\n",
    "mask_fn = os.path.join(mask_dir, \"mask.npz\")\n",
    "masks = np.load(mask_fn)[\"masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to arrays\n",
    "rgb_arr = np.array([np.array(x) for x in rgb_files])\n",
    "depth_arr = np.array([np.array(x)*depth_scaling for x in depth_files])\n",
    "\n",
    "# get a demo dict with one entry\n",
    "def get_demo_dict(i):\n",
    "    demo_dict = dict(rgb=rgb_arr[i:i+1],\n",
    "                     depth=depth_arr[i:i+1],\n",
    "                     mask=masks[i:i+1],\n",
    "                     keep=[1],\n",
    "                     state=np.ones((1,4)))\n",
    "    \n",
    "    return demo_dict\n",
    "\n",
    "def get_live_arg(i):\n",
    "    live_rgb = rgb_arr[i]\n",
    "    ee_pos = None\n",
    "    live_depth = depth_arr[i]\n",
    "    return live_rgb, ee_pos, live_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rgb, _, live_depth  = get_live_arg(0)\n",
    "print(live_depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = \"/home/argusm/CLUSTER/robot_recordings/pose_estimation\"\n",
    "save_dir = os.path.join(save_path,object_name)\n",
    "dm_fn = os.path.join(save_dir,\"dm.npz\")\n",
    "print(dm_fn)\n",
    "assert(os.path.isfile(dm_fn))\n",
    "dm_obj = np.load(dm_fn)\n",
    "\n",
    "T_wt = dm_obj[\"T_world2tcp\"]\n",
    "T_mc = dm_obj[\"T_marker2cam\"]\n",
    "def get_transform(i,j):\n",
    "    return T_mc[i] @ np.linalg.inv(T_mc[j])\n",
    "\n",
    "assert len(rgb_files) == len(T_mc)\n",
    "num_images = len(rgb_files)\n",
    "\n",
    "# get sorted upper triangular values\n",
    "dist_triu = np.triu_indices(num_images, 1)\n",
    "\n",
    "dm_rot = dm_obj[\"rot_marker\"]\n",
    "# get distance ids and values\n",
    "dist_rot_triu_values = dm_rot[dist_triu]\n",
    "dist_rot_order = np.argsort(dist_rot_triu_values)\n",
    "dist_ids = np.array(dist_triu).T[dist_rot_order]\n",
    "dist_rot_values = dist_rot_triu_values[dist_rot_order]\n",
    "\n",
    "print(dist_ids.shape)\n",
    "print(dist_rot_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_grasping.flow_control.servoing_fitting import solve_transform\n",
    "from gym_grasping.flow_control.servoing_module import ServoingModule\n",
    "\n",
    "# this needs to have sample data to see sizes\n",
    "default_demo = get_demo_dict(0)\n",
    "#camera_calibration = dict(width=640, height=480, \n",
    "#                          ppx=128.0, ppy=128.0,\n",
    "#                          fx=322.3224792221095, fy=322.3224792221095)\n",
    "camera_calibration = dict(width=640, height=480,\n",
    "                          ppx=315.20367431640625, ppy=245.70614624023438,\n",
    "                          fx=617.8902587890625, fy=617.8903198242188)\n",
    "\n",
    "\n",
    "class ServoingModuleFGR(ServoingModule):\n",
    "    def get_transform_pc(self, live_rgb, ee_pos, live_depth):\n",
    "        \"\"\"\n",
    "        get a transformation from a pointcloud using FGR.\n",
    "        \"\"\"\n",
    "        assert live_rgb.shape == self.base_image_rgb.shape\n",
    "        # 1. compute transformation\n",
    "        # for compatibility with notebook.\n",
    "        demo_rgb = self.base_image_rgb\n",
    "        demo_depth = self.base_image_depth\n",
    "        end_points = np.array(np.where(self.base_mask)).T\n",
    "\n",
    "        start_pc = self.generate_pointcloud2(live_rgb, live_depth)\n",
    "        end_pc = self.generate_pointcloud(demo_rgb, demo_depth, end_points)\n",
    "\n",
    "        # transform into TCP coordinates\n",
    "        T_tcp_cam = np.array([\n",
    "            [0.99987185, -0.00306941, -0.01571176, 0.00169436],\n",
    "            [-0.00515523, 0.86743151, -0.49752989, 0.11860651],\n",
    "            [0.015156, 0.49754713, 0.86730453, -0.18967231],\n",
    "            [0., 0., 0., 1.]])\n",
    "\n",
    "        start_pc[:, 0:4] = (T_tcp_cam @ start_pc[:, 0:4].T).T\n",
    "        end_pc[:, 0:4] = (T_tcp_cam @ end_pc[:, 0:4].T).T\n",
    "\n",
    "        reg_res = self.reg_module.register(start_pc, end_pc)\n",
    "        T_tp_t = reg_res.transformation\n",
    "        guess = T_tp_t\n",
    "        return guess\n",
    "\n",
    "sm = ServoingModuleFGR(default_demo, camera_calibration=camera_calibration)\n",
    "\n",
    "def estimate_transform(i, j):\n",
    "    demo_dict = get_demo_dict(i)\n",
    "    live_arg = get_live_arg(j)\n",
    "    sm.set_demo(demo_dict)\n",
    "    T_guess = sm.get_transform_pc(*live_arg)\n",
    "    return T_guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "dist_stop = 250\n",
    "dist_subsample = 1\n",
    "filename = os.path.join(save_dir, \"gt.npz\")\n",
    "print(filename)\n",
    "\n",
    "plot_ids = []\n",
    "rec = {}\n",
    "for ids in tqdm(dist_ids[:dist_stop:dist_subsample]):\n",
    "    i, j = ids\n",
    "    plot_ids.append(ids)\n",
    "    T_gt = get_transform(i, j)\n",
    "    if not np.all(np.isfinite(T_gt)):\n",
    "        continue\n",
    "    rec['{}_{}'.format(i,j)] = T_gt\n",
    "np.savez(filename,**rec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pose Esimtation Algorithm (takes time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = sm.method_name\n",
    "print(method_name)\n",
    "filename = os.path.join(save_dir, \"{}.npz\".format(method_name))\n",
    "rec = {}\n",
    "for ids in tqdm(dist_ids[:dist_stop:dist_subsample]):\n",
    "    i, j = ids    \n",
    "    T_gt = get_transform(i, j)\n",
    "    if not np.all(np.isfinite(T_gt)):\n",
    "        continue\n",
    "    T_guess = estimate_transform(i, j)\n",
    "    rec['{}_{}'.format(i,j)] = T_guess\n",
    "np.savez(filename,**rec)\n",
    "print(\"done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mia_dir = \"/misc/lmbraid19/zhouh/eval_wd40\"\n",
    "filenames = os.listdir(mia_dir)\n",
    "algo_names = (\"sift_mask\", \"deeptam\")\n",
    "algorithms = {}\n",
    "for algo in algo_names:\n",
    "    algorithms[algo] = os.path.join(mia_dir, '{}.npz'.format(algo))\n",
    "algo_names = (\"IRR_PWC\", \"FlowNet2\", \"FGR\")\n",
    "for algo in algo_names:\n",
    "    algorithms[algo] = os.path.join(save_dir, '{}.npz'.format(algo))\n",
    "# add zero prediction, so that we can use the same filtering code\n",
    "algorithms[\"zero\"] = None\n",
    "\n",
    "results = {}\n",
    "for algo, filename in algorithms.items():\n",
    "    if filename is not None:\n",
    "        file_obj = np.load(filename, allow_pickle=True)\n",
    "        file_format = \"dict\"\n",
    "        if 'arr_0' in file_obj:\n",
    "            result = file_obj['arr_0']\n",
    "            file_format = \"array\"\n",
    "        else:\n",
    "            result = file_obj\n",
    "            file_format = 'dict'\n",
    "    \n",
    "    pos_errs = []\n",
    "    rot_errs = []\n",
    "    pos_mags = []\n",
    "    rot_mags = []\n",
    "    \n",
    "    for ids in plot_ids:\n",
    "        i,j = ids\n",
    "        T_gt = get_transform(i, j)\n",
    "        assert(np.all(np.isfinite(T_gt)))\n",
    "        \n",
    "        if algo == \"zero\":\n",
    "            T_guess = np.eye(4)\n",
    "        elif file_format == \"array\":\n",
    "            T_guess = result[i+50*j]\n",
    "        elif file_format == 'dict':\n",
    "            T_guess = result['{}_{}'.format(i, j)]\n",
    "        else:\n",
    "            raise ValueError\n",
    "        if T_guess is None:\n",
    "            T_guess = np.eye(4)\n",
    "            \n",
    "        diff_pos = np.linalg.norm(T_gt[:3, 3]-T_guess[:3, 3], 2)\n",
    "        R_gt = T_gt[:3, :3]\n",
    "        R_ge = T_guess[:3, :3]\n",
    "        diff_rot = R.from_matrix(R_gt @ np.linalg.inv(R_ge)).magnitude()\n",
    "        \n",
    "        if diff_pos > .25:\n",
    "            diff_pos = .25\n",
    "            \n",
    "        pos_errs.append(diff_pos)\n",
    "        rot_errs.append(diff_rot)\n",
    "        pos_mags.append(np.linalg.norm(T_guess[:3,3]))\n",
    "        rot_mags.append(R.from_matrix(R_ge).magnitude())\n",
    "        \n",
    "    results[algo] = dict(pos=pos_errs, rot=rot_errs,\n",
    "                         pos_mag=pos_mags, rot_mag=rot_mags)\n",
    "    \n",
    "    print(\"done:\", algo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fig, ax = plt.subplots(1,figsize=(16,12))\n",
    "algo = \"IRR_PWC\"\n",
    "score = np.argsort(results[algo][\"rot\"])/len(results[algo][\"rot\"])\n",
    "score = np.array(results[algo][\"rot\"])\n",
    "im = sns.scatterplot(results[\"zero\"][\"rot\"], results[\"zero\"][\"pos\"], size=score, hue=score, label=\"error\")\n",
    "ax.set_xlabel(\"rot [rad]\")\n",
    "ax.set_ylabel(\"pos [m]\")\n",
    "#fig.colorbar(im, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "method_name = dict(FlowNet2=\"FlowNet2\",\n",
    "                   deeptam=\"DeepTAM\", \n",
    "                   sift_mask=\"SIFT\",\n",
    "                   zero=\"Zero\", IRR_PWC=\"IRR_PWC\",FGR=\"FGR\") \n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"increasing |R|\")\n",
    "ax.set_ylabel(\"error (rad)\")\n",
    "for k in method_name:\n",
    "    v = results[k]\n",
    "    ax.plot(v[\"rot\"], label=method_name[k])\n",
    "ax.legend()\n",
    "\n",
    "Xs = results[\"zero\"][\"rot\"]\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.set_xlabel(\"increasing |R|\")\n",
    "ax.set_ylabel(\"error (m)\")\n",
    "for k in method_name:\n",
    "    v = results[k]\n",
    "    ax.plot(v[\"pos\"], label=method_name[k])\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# rotation and position masking thresholds\n",
    "r_mask_t = np.pi/4\n",
    "p_mask_t = .25\n",
    "\n",
    "print(\"Number of samples:\", len(plot_ids))\n",
    "Xs = np.linspace(0, 1, len(plot_ids))\n",
    "\n",
    "linew = 3.5\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    print(\"\\nRotation: (AUC-higher is better)\")\n",
    "    fig, ax = plt.subplots(1, figsize=(4, 3))\n",
    "    for algo in method_name:\n",
    "        # find outliers to mask\n",
    "        r_mask = np.array(results[algo][\"rot_mag\"]) > r_mask_t\n",
    "        p_mask = np.array(results[algo][\"pos_mag\"]) > p_mask_t\n",
    "        cur_mask = np.logical_or(r_mask, p_mask)\n",
    "        # mask outliers\n",
    "        data = np.array(results[algo][\"rot\"])\n",
    "        data[cur_mask] = np.array(results[\"zero\"][\"rot\"])[cur_mask]\n",
    "        print(algo.ljust(10), 1-data.mean())\n",
    "        # plot\n",
    "        ax.plot(np.sort(data), Xs, label=method_name[algo], linewidth=linew)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"error (rad)\", size=18)\n",
    "    ax.set_xlim(0,.8)\n",
    "    #ax.legend(loc=\"lower right\")    \n",
    "    plt.savefig(\"/home/argusm/lang/flow_control/relative_orientation_error.pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "    print(\"\\nTranslation:\")\n",
    "    fig, ax = plt.subplots(1, figsize=(4, 3))\n",
    "    for algo in method_name:\n",
    "        r_mask = np.array(results[algo][\"rot_mag\"]) > r_mask_t\n",
    "        p_mask = np.array(results[algo][\"pos_mag\"]) > p_mask_t\n",
    "        cur_mask = np.logical_or(r_mask, p_mask)\n",
    "        data = np.array(results[algo][\"pos\"])\n",
    "        data[cur_mask] = np.array(results[\"zero\"][\"pos\"])[cur_mask]\n",
    "        print(algo.ljust(10), 1-data.mean())\n",
    "        ax.plot(np.sort(data)*1000, Xs, label=method_name[algo], linewidth=linew)\n",
    "    ax.set_xlim(0, 250)\n",
    "    ax.set_xlabel(\"error (mm)\", size=18)\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    plt.savefig(\"/home/argusm/lang/flow_control/relative_translation_error.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Outlier Inspection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib inline\n",
    "bad_samples = np.where(np.array(rot_diffs)>3)[0]\n",
    "print(bad_samples[1])\n",
    "i,j = plot_ids[bad_samples[1]]\n",
    "print(i,j)\n",
    "\n",
    "T_gt = get_transform(i, j)\n",
    "demo_dict = get_demo_dict(i)\n",
    "sm.set_demo(demo_dict)\n",
    "live_arg = get_live_arg(j)\n",
    "# print(\"actual\")\n",
    "# plt.imshow(rgb_arr[i])\n",
    "# plt.show()\n",
    "# print(\"demo_dict\")\n",
    "# plt.imshow(demo_dict[\"rgb\"][0])\n",
    "# plt.show()\n",
    "with sns.axes_style(\"white\"):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(16, 12))\n",
    "    ax[0].set_axis_off()\n",
    "    ax[1].set_axis_off()\n",
    "    ax[2].set_axis_off()\n",
    "    print(\"set\")\n",
    "    ax[0].imshow(sm.base_image_rgb)\n",
    "    print(\"live\")\n",
    "    ax[1].imshow(live_arg[0])\n",
    "    T_guess = sm.get_transform_pc(*live_arg)\n",
    "    flow = sm.flow_module.step(sm.base_image_rgb, live_arg[0])\n",
    "    flow_img = sm.flow_module.computeImg(flow, dynamic_range=False)\n",
    "    ax[2].imshow(flow_img)\n",
    "    plt.subplots_adjust(wspace=.01)\n",
    "    plt.savefig(\"/home/argusm/lang/flow_control/bad_flow_example.png\",bbox_inches=\"tight\",dpi=50)\n",
    "    plt.show()\n",
    "\n",
    "R_gt = T_gt[:3,:3]\n",
    "R_guess = T_guess[:3,:3]\n",
    "\n",
    "diff_rot = R.from_matrix(R_gt @ np.linalg.inv(R_guess)).magnitude()\n",
    "print(diff_rot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pcd_list = []\n",
    "masks = []\n",
    "i = 0\n",
    "for rgb_file, depth_file, T in tqdm(zip(rgb_files, depth_files, T_mc)):\n",
    "    if np.any(np.isnan(T)):\n",
    "        # mask all, so that our lists stay alligned\n",
    "        w, h = camera_calibration_d[\"width\"], camera_calibration_d[\"height\"]\n",
    "        mask_all = np.zeros((h, w),dtype=bool)\n",
    "        masks.append(mask_all)\n",
    "        continue\n",
    "    rgb = o3d.geometry.Image(np.array(rgb_file))\n",
    "    depth = np.array(depth_file) * depth_scaling\n",
    "    depth = o3d.geometry.Image(depth.astype(np.float32))\n",
    "    rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(rgb, depth,\n",
    "                                          depth_scale=1.0, depth_trunc=1.0,\n",
    "                                          convert_rgb_to_intensity=False)\n",
    "\n",
    "    pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, K_o3d)\n",
    "    pcd.transform(np.linalg.inv(T))\n",
    "    pcd = crop_all(pcd)\n",
    "    pcd_list.append(pcd)\n",
    "    \n",
    "    #pcb_back = o3d.geometry.PointCloud(pcd)\n",
    "    pcd_back = pcd.transform(T)\n",
    "    mask = points_to_mask(pcd_back)\n",
    "    masks.append(mask)\n",
    "    \n",
    "\n",
    "pcd_all = pcd_list[0]\n",
    "for pcd_cur in pcd_list[1:]:\n",
    "    pcd_all += pcd_cur\n",
    "\n",
    "o3d.visualization.draw_geometries([pcd_all])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
