{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventions\n",
    "\n",
    "0. Use multiply on *left* convention: T(x) = A @ x ( column vectors)\n",
    "1. The Z axis is going out of the camera, meaning clockwise == positive\n",
    "2. If the object moves anit-clockwise, the camera is moving clockwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib notebook\n",
    "import getpass \n",
    "from ipywidgets import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "username = getpass. getuser() \n",
    "if username == \"argusm\":\n",
    "    recording_dir = \"/home/argusm/tmp/control_test\"\n",
    "else:\n",
    "    recording_dir = \"/media/kuka/Seagate Expansion Drive/kuka_recordings/flow/control_test\"\n",
    "    \n",
    "episode_num = 1\n",
    "recording_fn = \"{}/episode_{}.npz\".format(recording_dir, episode_num)\n",
    "mask_recording_fn = \"{}/episode_{}_mask.npz\".format(recording_dir, episode_num)\n",
    "keep_fn = \"{}/episode_{}_keep.npz\".format(recording_dir, episode_num)\n",
    "\n",
    "recording_dict = np.load(recording_fn)\n",
    "image_recording = recording_dict[\"rgb_unscaled\"]\n",
    "depth_recording = recording_dict[\"depth_imgs\"]\n",
    "state_recording = recording_dict[\"robot_state_full\"]\n",
    "ee_positions = state_recording[:,:3]\n",
    "actions = recording_dict[\"actions\"]\n",
    "\n",
    "num_frames = image_recording.shape[0]-1\n",
    "masks = np.load(mask_recording_fn)[\"mask\"]\n",
    "np.savez(keep_fn, keep=np.ones(num_frames,dtype=bool))\n",
    "\n",
    "print(list(recording_dict.keys()))\n",
    "print(mask_recording_fn)\n",
    "print(state_recording.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot masked video\n",
    "plot_masked_video = True\n",
    "if plot_masked_video:\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    line = ax.imshow(masks[25])\n",
    "    ax.set_axis_off()\n",
    "\n",
    "    def update(i):\n",
    "        image = image_recording[i].copy()\n",
    "        mask = masks[i]\n",
    "        image[np.logical_not(mask)] = 255,255,255\n",
    "        line.set_data(image)\n",
    "        fig.canvas.draw_idle()\n",
    "\n",
    "    slider_i2 = widgets.IntSlider(min=0,max=num_frames,step=1,value=25,\n",
    "                                 layout=Layout(width='70%'))\n",
    "\n",
    "    interact(update, i=slider_i2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_grasping.flow_control.servoing_module import ServoingModule\n",
    "servo_module = ServoingModule(recording_dir, episode_num=episode_num, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_frame = 136\n",
    "target_frame = 137\n",
    "#start_frame = 170\n",
    "#target_frame = 180\n",
    "servo_module.set_base_frame(target_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_two_frames = True\n",
    "if plot_two_frames:\n",
    "    image_start = image_recording[start_frame].copy()\n",
    "#     image_start[np.logical_not(masks[start_frame])] = 255\n",
    "    image_target = image_recording[target_frame].copy()\n",
    "#     image_target[np.logical_not(masks[target_frame])] = 255\n",
    "\n",
    "    fig, ax = plt.subplots(1,1)\n",
    "    plt_handle = ax.imshow(image_start)\n",
    "    ax.set_axis_off()\n",
    "    def update(i):\n",
    "        if i == 0:\n",
    "            plt_handle.set_data(image_start)\n",
    "        if i == 1:\n",
    "            plt_handle.set_data(image_target)\n",
    "        fig.canvas.draw_idle()\n",
    "    slider_i2 = widgets.IntSlider(min=0,max=1, step=1,value=0,\n",
    "                                 layout=Layout(width='70%'))\n",
    "    interact(update, i=slider_i2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips \n",
    "1. The Z axis is going out of the camera, meaning clockwise == positive\n",
    "2. If the object moves anit-clockwise, the camera is moving clockwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import pi\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Points_tcp = T_tcp_cam @ Points_cam \n",
    "T_tcp_cam = np.array([\n",
    " [ 0.99987185, -0.00306941, -0.01571176,  0.00169436],\n",
    " [-0.00515523,  0.86743151, -0.49752989,  0.11860651],\n",
    " [ 0.015156,    0.49754713,  0.86730453, -0.18967231],\n",
    " [ 0.,          0.,          0.,          1.        ]])\n",
    "\n",
    "def kuka2dcm(data):\n",
    "    xyz = data[0:3]\n",
    "    r = R.from_euler('ZYX', data[3:6], degrees=False)\n",
    "    dcm = np.eye(4)\n",
    "    dcm[:3,3] = xyz\n",
    "    dcm[:3,:3] = r.as_matrix()\n",
    "    return dcm\n",
    "\n",
    "def dcm2pretty(dcm):\n",
    "    trn = dcm[:3,3]\n",
    "    rot = R.from_dcm(dcm[:3,:3]).as_euler('xyz')\n",
    "    return np.concatenate((trn,rot)).round(3)\n",
    "\n",
    "# state has the structure: x,y,z,rot_z,rot_y,rot_x, joint[0-6], desired tcp pos x,y,z, rot_z, force x,y,z, torque x,y,z\n",
    "start_state = state_recording[start_frame][0:6]\n",
    "target_state = state_recording[target_frame][0:6]\n",
    "transformation_gt_lin = -start_state  + target_state\n",
    "\n",
    "S = kuka2dcm(start_state)\n",
    "T = kuka2dcm(target_state)\n",
    "S2T = np.linalg.inv(S) @ T\n",
    "pose_gt = S2T\n",
    "\n",
    "transformation_gt = S2T\n",
    "print(\"start\", start_state.round(3))\n",
    "print(\"targt\", target_state.round(3))\n",
    "print()\n",
    "print(\"lin\", transformation_gt_lin.round(3))\n",
    "print(\"gt \", dcm2pretty(S2T), \"in TCP coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym_grasping.flow_control.servoing_fitting import solve_transform\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "\n",
    "# start\n",
    "start_image = image_recording[start_frame]\n",
    "start_depth = depth_recording[start_frame]\n",
    "start_ee_pos = ee_positions[start_frame]\n",
    "# target\n",
    "end_image = image_recording[target_frame]\n",
    "end_depth = depth_recording[target_frame]\n",
    "end_mask = masks[target_frame]\n",
    "\n",
    "# backward flow goes from (end_points -> start_points)\n",
    "flow = servo_module.flow_module.step(end_image, start_image)\n",
    "end_points = np.array(np.where(end_mask)).T\n",
    "masked_flow = flow[end_mask]\n",
    "start_points = end_points + masked_flow[:, ::-1].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting without depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting code\n",
    "end_points_hom = np.pad(end_points.astype('float'), ((0, 0), (0, 2)), mode=\"constant\")\n",
    "start_points_hom = np.pad(start_points.astype('float'), ((0, 0), (0, 2)), mode=\"constant\")\n",
    "#start_points_hom[:,0:4] = (T_tcp_cam @ start_points_hom[:,0:4].T).T\n",
    "#end_points_hom[:,0:4] = (T_tcp_cam @ end_points_hom[:,0:4].T).T\n",
    "\n",
    "# Trf. from camera(t+1) <- camera(t)\n",
    "T_cp_c = solve_transform(start_points_hom, end_points_hom)\n",
    "\n",
    "print(\"gt \", dcm2pretty(pose_gt))\n",
    "print(\"img\", dcm2pretty(T_cp_c))\n",
    "print(\"img\", dcm2pretty(T_tcp_cam @ T_cp_c @ np.linalg.inv(T_tcp_cam)), \"in TCP coordinates\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting with depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_X = 315.20367431640625\n",
    "C_Y = 245.70614624023438\n",
    "FOC_X = 617.8902587890625\n",
    "FOC_Y = 617.8903198242188\n",
    "print(\"T_tcp_cam euler angles\", R.from_dcm(T_tcp_cam[:3,:3]).as_euler('xyz'))\n",
    "\n",
    "def generate_pointcloud(rgb_image, depth_image, masked_points):\n",
    "    pointcloud = []\n",
    "    for u, v in masked_points:\n",
    "        try:\n",
    "            Z = depth_image[u, v] * 0.000125\n",
    "            color = rgb_image[u, v]\n",
    "        except IndexError:\n",
    "            Z = 0\n",
    "            color = 0,0,0\n",
    "        X = (v - C_X) * Z / FOC_X\n",
    "        Y = (u - C_Y) * Z / FOC_Y\n",
    "        pointcloud.append([X, Y, Z, 1, *color])\n",
    "    pointcloud = np.array(pointcloud)\n",
    "    return pointcloud\n",
    "\n",
    "K = np.array([[617.89, 0, 315.2, 0 ],\n",
    "              [0, 617.89, 245.7, 0 ],\n",
    "              [0, 0, 1, 0]])\n",
    "\n",
    "def project(K, X):\n",
    "    x = K @ X\n",
    "    return x[0:2] / x[2]\n",
    "\n",
    "start_pc = generate_pointcloud(start_image, start_depth, start_points)\n",
    "end_pc = generate_pointcloud(end_image, end_depth, end_points)\n",
    "\n",
    "mask_pc = np.logical_and( start_pc[:,2]!=0 , end_pc[:,2] !=0 )\n",
    "mask_pc = np.logical_and( mask_pc, np.random.random(mask_pc.shape[0])>.95) \n",
    "\n",
    "start_pc = start_pc[mask_pc]\n",
    "end_pc = end_pc[mask_pc]\n",
    "\n",
    "# transform into TCP coordinates\n",
    "start_pc[:,0:4] = (T_tcp_cam @ start_pc[:,0:4].T).T\n",
    "end_pc[:,0:4] = (T_tcp_cam @ end_pc[:,0:4].T).T\n",
    "\n",
    "if False:\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    fig = plt.figure()\n",
    "    ax = Axes3D(fig)\n",
    "    ax.set_xlim3d(-.15, 0.15)\n",
    "    ax.set_ylim3d(-.15, 0.15)\n",
    "    ax.set_zlim3d(0, 0.3)\n",
    "    ax.scatter(np.reshape(start_pc[:,0], -1), np.reshape(start_pc[:,1], -1),np.reshape(start_pc[:,2], -1), c=start_pc[:,3:6]/255)\n",
    "    ax.scatter(np.reshape(end_pc[:,0], -1), np.reshape(end_pc[:,1], -1),np.reshape(end_pc[:,2], -1), c=end_pc[:,3:6][:,::-1]/255)\n",
    "    for i in np.linspace(0,.1,10):\n",
    "        ax.scatter(0,0,-i)\n",
    "    plt.show()\n",
    "    \n",
    "T_tp_t = solve_transform(start_pc[:,0:4], end_pc[:,0:4])\n",
    "\n",
    "print(\"gt \", dcm2pretty(pose_gt))\n",
    "print(\"dpt\", dcm2pretty(np.linalg.inv(T_tp_t)))\n",
    "\n",
    "print(\"guess  rot\", dcm2pretty(np.linalg.inv(T_tp_t))[5])\n",
    "print(\"action rot\", actions[start_frame][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Center of Rotation from Image\n",
    "This code finds the center of rotation in image plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_img = servo_module.flow_module.computeImg(flow, dynamic_range=False)\n",
    "flow_norm = np.linalg.norm(flow, axis=2)\n",
    "# show segmentatione edge\n",
    "\n",
    "h, w, _ = flow.shape\n",
    "ch, cw = h/2, w/2\n",
    "\n",
    "from skimage.feature import peak_local_max\n",
    "d = 50\n",
    "subsection = flow_norm[int(ch)-d:int(ch)+d,int(cw)-d:int(cw)+d]\n",
    "peak_h,peak_w = peak_local_max(-subsection)[0]\n",
    "dh, dw = peak_h - d, peak_w - d\n",
    "\n",
    "# show loss, frame number\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(flow_img)\n",
    "ax.scatter(cw, ch, s=25, c='red', marker='x')\n",
    "ax.scatter(cw+dw, ch+dh, s=25, c='green', marker='x')\n",
    "plt.show()\n",
    "\n",
    "#ax.imshow(subsection)\n",
    "#ax.scatter(dw,dh,s=25,c='red', marker='x')\n",
    "print(\"delta height, width:\", dh,dw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
